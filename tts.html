<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Voiceglow HTML Sample</title>
    <!-- CSS Styles -->

</head>
<body>
    <h1>Voiceglow HTML Sample</h1>
    <p>This is basically your website here :)</p>
    <p>Did you know that the strongest muscle in the body is the tongue?</p>


    <div style="width: 500; height: 500;" id="VG_OVERLAY_CONTAINER">
        <!-- Here is where Voiceglow renders the widget. -->
        <!-- Set render to 'full-width' then adjust the width and height to 500px (for example) to render the chatbot itself without the popup. -->
    </div>

    <!-- Remove 'defer' if you want widget to load faster (Will affect website loading) -->
    <script defer>
    (function() {
        document.querySelector('html').style.fontSize = "16px"; // 16px is the default value, this is needed now for fully eliminating spacing issues.
        window.VG_CONFIG = {
            ID: "15aqom7q7",
            region: 'na', // 'eu' or 'na' corresponding to Europe and North America
            render: 'full-width', // popup or full-width
            stylesheets: [
                // Base Voiceglow CSS
                "https://storage.googleapis.com/speakwiz-app.appspot.com/vg_live_build/styles.css",
                // Add your custom css stylesheets, Can also add relative URL ('/public/your-file.css)
            ],
        }
        var VG_SCRIPT = document.createElement("script");
        VG_SCRIPT.src = "https://storage.googleapis.com/speakwiz-app.appspot.com/vg_live_build/vg_bundle.js";
        document.body.appendChild(VG_SCRIPT);
    })()
    </script>

    <script>
// Check for browser compatibility and request microphone permissions
if (window.hasOwnProperty('webkitSpeechRecognition')) {
  const recognition = new webkitSpeechRecognition();

  recognition.continuous = false; // Stop recording on first pause
  recognition.interimResults = false;
  recognition.lang = 'en-US';

  let finalTranscript = ''; // Variable to hold the final transcript

  // Request microphone permissions
  navigator.mediaDevices.getUserMedia({ audio: true })
    .then(() => {
      console.log('Microphone permission granted.');
    })
    .catch((error) => {
      console.error('Microphone permission denied:', error);
      // Handle permission denial
    });

  function startDictation() {
    recognition.start();

    // Use addEventListener for better reliability
    window.addEventListener('keyup', stopDictation, { once: true });
  }

  function stopDictation(event) {
    if (event.code === 'Space') {
      recognition.stop();

      const chatInput = document.getElementById('VG_TEXT_INPUT_CHATBOT');
      if (chatInput && finalTranscript) {
        chatInput.focus();
        chatInput.value = finalTranscript;
        chatInput.dispatchEvent(new Event('input', { bubbles: true }));
        chatInput.dispatchEvent(new KeyboardEvent('keypress', { 'key': 'Enter' }));
      }

      finalTranscript = '';
    } else {
      console.log('Ignoring keyup event:', event.code); // Log non-space key events
    }
  }

  recognition.onresult = function (e) {
    finalTranscript += e.results[0][0].transcript; // Append the latest text
  };

  recognition.onerror = function (e) {
    console.error('Speech recognition error:', e);
  };

function observeChatInput() {
  // **Code to observe chat input changes:**
  // - Use a MutationObserver or a polling mechanism to detect changes in the chat input's value.
  // - If the value is cleared, you might want to reset it to a default message or trigger other actions.
  // - Example using MutationObserver:
  const chatInput = document.getElementById('VG_TEXT_INPUT_CHATBOT');
  const observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.type === 'attributes' && mutation.attributeName === 'value') {
        const currentValue = chatInput.value;
        if (currentValue === '') {
          // Handle cleared input
        }
      }
    });
  });
  observer.observe(chatInput, { attributes: true, attributeFilter: ['value'] });
}

function addMicrophoneButton() {
  // **Code to add the microphone button to the widget:**
  // - Create a button element using JavaScript.
  // - Set the button's content to a microphone icon or text.
  // - Attach an event listener to the button's click event to call the `startDictation` function.
  // - Append the button to the appropriate container within your widget's structure.
  // - Example:
  const micButton = document.createElement('button');
  micButton.innerHTML = ''; // Microphone emoji
  micButton.onclick = startDictation;
  const actionContainer = document.querySelector('.vg-footer-icons-container'); // Replace with the actual selector for your widget's action container
  if (actionContainer) {
    actionContainer.appendChild(micButton);
  } else {
    console.error('Chat widget action container not found');
  }
}

  window.addEventListener('load', function () {
    setTimeout(function () {
      observeChatInput();
      addMicrophoneButton();
    }, 5000); // Adjust the delay as needed
  });
} else {
  console.error('Speech recognition not supported in this browser.');
  // Provide fallback mechanism for non-supporting browsers
}
</script>
</body>
</html>
